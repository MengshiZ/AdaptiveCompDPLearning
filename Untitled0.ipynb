{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1PYn4KrKubs64iY5_uSoaj-rgB72-A4qb","authorship_tag":"ABX9TyPdciaCAgNgPVJP9Lrx7yuC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# ---- Python standard library ----\n","import math\n","from collections import defaultdict\n","\n","# ---- Numerical computing ----\n","import numpy as np\n","\n","# ---- PyTorch core ----\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# ---- PyTorch data utilities ----\n","from torch.utils.data import DataLoader\n","\n","# ---- Torchvision datasets & transforms ----\n","from torchvision import datasets, transforms"],"metadata":{"id":"EdRBFmXVY0i7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"A1n6dibZy2D7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","class NaiveDPQuery:\n","\n","\n","    def __init__(self, dim, epsilon,delta, seed=None):\n","        self.dim = dim\n","        self.epsilon=epsilon\n","        self.delta=delta\n","        self.rng = np.random.default_rng(seed)\n","        self.sigma=math.sqrt(math.log(1.25/self.delta))/self.epsilon\n","\n","        self.value = 0\n","        self.t=0\n","\n","\n","    # -------------------------\n","    def update(self, x):\n","\n","        x = np.asarray(x, dtype=float)\n","        assert x.shape == (self.dim,)\n","\n","        # advance time; now t is in {1, 2, 3, ...}\n","        self.t += 1\n","        t = self.t\n","\n","        # update true prefix sum (for debugging / non-DP use)\n","        self.value = x.copy()  # index 1\n","\n","\n","    # -------------------------\n","    def single_query(self):\n","      fresh_noise= self.rng.normal(\n","                    0.0, self.sigma, size=self.dim\n","                )\n","      return self.value+fresh_noise\n","\n"],"metadata":{"id":"vG9GrdGPqWLa"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zh_Fzij1AcYN"},"outputs":[],"source":["import numpy as np\n","from collections import defaultdict\n","\n","\n","class DPPreSumQuery:\n","\n","\n","    def __init__(self, dim, epsilon,delta, seed=None):\n","        self.dim = dim\n","        self.epsilon=epsilon\n","        self.delta=delta\n","        self.rng = np.random.default_rng(seed)\n","        self.sigma=2*math.sqrt(2*math.log(2.5/self.delta))/self.epsilon\n","\n","        # current time, starting from 0 so the first update is at t = 1\n","        self.t = 0\n","\n","        # true_prefix[t] = sum from time 1 to t\n","        # We will ignore index 0 so that true_prefix[1] is the first prefix.\n","        self.true_prefix = 0\n","\n","        # base -> checkpoint noise (for the entire phase starting at `base`)\n","        self.checkpoint_noise = {}\n","\n","        # base -> {(level, index) -> noise}\n","        # where each entry corresponds to a dyadic interval in the tail:\n","        #   level ℓ, index i  => interval of length 2^ℓ\n","        #   over times [base + 1 + i*2^ℓ, ..., base + (i+1)*2^ℓ]\n","        self.tail_tree_noise = defaultdict(dict)\n","\n","        # current phase base time (will be set when we hit the first base)\n","        self.current_base = None\n","\n","        self.prev_query= None\n","\n","    # -------------------------\n","    def update(self, x):\n","\n","        x = np.asarray(x, dtype=float)\n","        assert x.shape == (self.dim,)\n","\n","        # advance time; now t is in {1, 2, 3, ...}\n","        self.t += 1\n","        t = self.t\n","\n","        # update true prefix sum (for debugging / non-DP use)\n","        if t == 1:\n","            self.true_prefix = x.copy()  # index 1\n","            self.prev_query = 0\n","        else:\n","            self.prev_query =self.query()\n","            self.true_prefix += x.copy()\n","\n","\n","        if (t + 1) & t == 0:\n","            base = t\n","\n","            # one noise vector for the whole phase, used at every query ≥ base\n","            self.checkpoint_noise[base] = self.rng.normal(\n","                0.0, self.sigma, size=self.dim\n","            )\n","\n","            # reset tail-tree for this new phase\n","            self.tail_tree_noise[base] = {}\n","            self.current_base = base\n","\n","\n","            return\n","\n","\n","        if self.current_base is None:\n","            return\n","\n","        base = self.current_base\n","        # Tail starts at time base+1; define offset so that:\n","        #   offset = 0 corresponds to time base+1\n","        offset = t - (base + 1)\n","\n","\n","        o = offset\n","        while o >= 0:\n","            # largest power-of-two \"lowbit\" of (o+1)\n","            lowbit = (o + 1) & (-(o + 1))\n","            length = lowbit              # 2^level\n","            # level = log2(length)\n","            block_level = length.bit_length() - 1\n","            # start offset of this block\n","            start_offset = o + 1 - length\n","            # index within this level\n","            index = start_offset // length\n","            key = (block_level, index)\n","\n","            # Assign noise for this block if not already created\n","            if key not in self.tail_tree_noise[base]:\n","                self.tail_tree_noise[base][key] = self.rng.normal(\n","                    0.0, self.sigma*math.sqrt(math.log(self.current_base)), size=self.dim\n","                )\n","\n","            # Move to the remaining prefix [0, start_offset - 1]\n","            o = start_offset - 1\n","\n","    # -------------------------\n","    def query(self):\n","        \"\"\"\n","        Return (true_prefix[tau] + noise) using\n","        - a checkpoint at base\n","        - plus tail-tree intervals covering (base, tau].\n","\n","        tau is a 1-based time index.\n","        \"\"\"\n","        tau = self.t\n","\n","        if tau < 1 or tau > self.t:\n","            raise ValueError(\"Invalid query time\")\n","\n","        # deterministic true sum\n","        result = self.true_prefix.copy()\n","\n","\n","        m = tau + 1\n","        largest_pow_two = 1 << (m.bit_length() - 1)  # 2^k ≤ m\n","        base = largest_pow_two - 1\n","\n","        # Add checkpoint noise for this phase\n","        ck = self.checkpoint_noise.get(base)\n","        if ck is not None:\n","            result += ck\n","\n","        if tau > base:\n","            offset = tau - (base + 1)\n","            o = offset\n","\n","            # Same lowbit-style decomposition as in update()\n","            while o >= 0:\n","                lowbit = (o + 1) & (-(o + 1))\n","                length = lowbit\n","                block_level = length.bit_length() - 1\n","                start_offset = o + 1 - length\n","                index = start_offset // length\n","                key = (block_level, index)\n","                noise = self.tail_tree_noise[base].get(key)\n","                if noise is not None:\n","                    result += noise\n","                o = start_offset - 1\n","\n","        return result\n","\n","    def single_query(self):\n","      return self.query()-self.prev_query\n"]},{"cell_type":"code","source":["demo=NaiveDPQuery(1,epsilon=10000,delta=1)\n","#NaiveDPQuery\n","#DPPreSumQuery"],"metadata":{"id":"I0IFuvU5unO9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(100):\n","  demo.update([i])"],"metadata":{"id":"r56J9rdVunSS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["demo.single_query()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qGCqj1A9unUh","executionInfo":{"status":"ok","timestamp":1768298516172,"user_tz":-480,"elapsed":6,"user":{"displayName":"Mengshi ZHAO","userId":"09447597087433299627"}},"outputId":"023103e1-8664-4f7e-efba-f88f69272203"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([98.99993858])"]},"metadata":{},"execution_count":301}]},{"cell_type":"code","source":["def flatten_grads(model):\n","    grads = []\n","    for p in model.parameters():\n","        if p.grad is None:\n","            grads.append(torch.zeros_like(p).view(-1))\n","        else:\n","            grads.append(p.grad.view(-1))\n","    return torch.cat(grads)\n","\n","def unflatten_grads(model, flat_grad):\n","    idx = 0\n","    for p in model.parameters():\n","        numel = p.numel()\n","        grad_view = flat_grad[idx:idx + numel].view_as(p)\n","\n","        if p.grad is None:\n","            # create a buffer once\n","            p.grad = torch.empty_like(p)\n","        # copy into existing grad tensor (in-place)\n","        p.grad.copy_(grad_view)\n","        idx += numel"],"metadata":{"id":"2buyjiLRRafw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class MLP(nn.Module):\n","    def __init__(self, input_dim=28*28, hidden=256, num_classes=47):\n","        super().__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden)\n","        self.fc2 = nn.Linear(hidden, hidden)\n","        self.fc3 = nn.Linear(hidden, num_classes)\n","\n","    def forward(self, x):\n","        x = x.view(x.size(0), -1)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        return self.fc3(x)"],"metadata":{"id":"4UBS6FbVTYgO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class SimpleCNN(nn.Module):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        num_classes: int,\n","        kernel_size: int = 3\n","    ):\n","        super().__init__()\n","\n","        padding = kernel_size // 2\n","\n","        self.features = nn.Sequential(\n","            nn.Conv2d(in_channels, 32, kernel_size, padding=padding),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(32, 64, kernel_size, padding=padding),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(2),\n","\n","            nn.Conv2d(64, 128, kernel_size, padding=padding),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(128, 128, kernel_size, padding=padding),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(2),\n","        )\n","\n","        # Makes model work for both 28×28 and 32×32\n","        self.avgpool = nn.AdaptiveAvgPool2d((4, 4))\n","\n","        self.classifier = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(128 * 4 * 4, 256),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(256, num_classes),\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.avgpool(x)\n","        x = self.classifier(x)\n","        return x\n","\n"],"metadata":{"id":"PGkT1yRtbfwD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.func import functional_call, vmap, grad\n","\n","# --- Corrected Trainer ---\n","class NormalTrainer:\n","    def __init__(self, model, optimizer, max_grad_norm, device=\"cpu\"):\n","        self.model = model.to(device)\n","        self.optimizer = optimizer\n","        self.device = device\n","        self.max_grad_norm = max_grad_norm\n","\n","    def train_batch(self, x, y, loss_fn):\n","        self.model.train()\n","        x, y = x.to(self.device), y.to(self.device)\n","        B = x.shape[0]\n","\n","        params_dict = dict(self.model.named_parameters())\n","        buffers_dict = dict(self.model.named_buffers())\n","        param_names = list(params_dict.keys())\n","\n","        def loss_per_sample(params, buffers, x_s, y_s):\n","            preds = functional_call(self.model, (params, buffers), (x_s.unsqueeze(0),))\n","            loss = loss_fn(preds, y_s.unsqueeze(0))\n","            return loss.mean()  # robust to reduction=\"none\"\n","\n","        # log the pre-step (true) batch loss for reporting\n","        with torch.no_grad():\n","            report_loss = loss_fn(self.model(x), y).item()\n","\n","        grad_fn = grad(loss_per_sample)\n","        per_sample_grads = vmap(grad_fn, in_dims=(None, None, 0, 0))(params_dict, buffers_dict, x, y)\n","\n","        # flatten\n","        flat_list = [per_sample_grads[name].reshape(B, -1) for name in param_names]\n","        flat = torch.cat(flat_list, dim=1)\n","\n","        norms = flat.norm(2, dim=1)\n","        factors = torch.clamp(self.max_grad_norm / (norms + 1e-6), max=1.0)\n","        flat = flat * factors.unsqueeze(1)\n","        avg = flat.mean(dim=0)\n","\n","        self.optimizer.zero_grad(set_to_none=True)\n","        idx = 0\n","        for name in param_names:\n","            p = params_dict[name]\n","            n = p.numel()\n","            g = avg[idx:idx+n].reshape_as(p)\n","            p.grad = g.detach().clone()\n","            idx += n\n","\n","        self.optimizer.step()\n","        return report_loss\n"],"metadata":{"id":"Lcs6qol1Vx9X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gc\n","import torch\n","from torch.func import functional_call, vmap, grad\n","\n","class DPSGDTrainer:\n","    def __init__(self, model, optimizer, epsilon, delta, max_grad_norm, dp_mechanism, device=\"cpu\", seed=0):\n","        self.model = model.to(device)\n","        self.optimizer = optimizer\n","        self.device = device\n","        self.epsilon = epsilon\n","        self.delta = delta\n","        self.seed = seed\n","        self.max_grad_norm = max_grad_norm\n","        self.dp_mechanism = dp_mechanism\n","\n","        # We calculate grad_dim based on the parameter count directly\n","        self.grad_dim = sum(p.numel() for p in self.model.parameters())\n","\n","        self.mechanism = self._new_mechanism()\n","        self.step = 0\n","\n","    def _new_mechanism(self):\n","        if self.dp_mechanism == 'DPPreSum':\n","            return DPPreSumQuery(\n","                dim=self.grad_dim,\n","                epsilon=self.epsilon,\n","                delta=self.delta,\n","                seed=self.seed\n","            )\n","        else:\n","            return NaiveDPQuery(dim=self.grad_dim, epsilon=self.epsilon, delta=self.delta, seed=self.seed)\n","\n","    def reset_presum(self):\n","        self.mechanism = None\n","        self.step = 0\n","        gc.collect()\n","        self.mechanism = self._new_mechanism()\n","\n","    def train_batch(self, x, y, loss_fn):\n","        self.model.train()\n","        x, y = x.to(self.device), y.to(self.device)\n","        batch_size = x.shape[0]\n","\n","        # ---- functional model state ----\n","        params_dict = dict(self.model.named_parameters())\n","        buffers_dict = dict(self.model.named_buffers())\n","\n","        # FIX: Create a fixed list of names to ensure consistent ordering\n","        param_names = list(params_dict.keys())\n","\n","        def loss_per_sample(params, buffers, x_s, y_s):\n","            preds = functional_call(\n","                self.model,\n","                (params, buffers),\n","                (x_s.unsqueeze(0),)\n","            )\n","            return loss_fn(preds, y_s.unsqueeze(0))\n","\n","        # ---- per-sample gradients (vectorized) ----\n","        grad_fn = grad(loss_per_sample)\n","        per_sample_grads = vmap(\n","            grad_fn,\n","            in_dims=(None, None, 0, 0)\n","        )(params_dict, buffers_dict, x, y)\n","\n","        # ---- flatten per-sample grads: [B, D] ----\n","        flat_grads_list = []\n","        # FIX: Iterate over the fixed list `param_names`\n","        for name in param_names:\n","            g = per_sample_grads[name]\n","            flat_grads_list.append(g.reshape(batch_size, -1))\n","        flat_grads = torch.cat(flat_grads_list, dim=1)\n","\n","        # ---- per-sample clipping ----\n","        grad_norms = torch.norm(flat_grads, p=2, dim=1)\n","        clip_factors = torch.clamp(\n","            self.max_grad_norm / (grad_norms + 1e-6),\n","            max=1.0\n","        )\n","        flat_grads = flat_grads * clip_factors.unsqueeze(1)\n","\n","        # ---- sum across batch ----\n","        summed_grad = flat_grads.sum(dim=0)\n","\n","        # ---- YOUR privacy mechanism (UNCHANGED) ----\n","        summed_grad_np = summed_grad.detach().cpu().numpy()\n","        self.mechanism.update(summed_grad_np)\n","        noisy_sum = self.mechanism.single_query()\n","\n","        self.step += 1\n","\n","        # ---- average after noise ----\n","        noisy_avg_grad = torch.tensor(\n","            noisy_sum / batch_size,\n","            device=self.device,\n","            dtype=summed_grad.dtype # Ensure dtype match\n","        )\n","\n","        # ---- apply gradient ----\n","        self.optimizer.zero_grad()\n","\n","        # FIX: Manually unflatten using the SAME `param_names` list\n","        current_idx = 0\n","        for name in param_names:\n","            param = params_dict[name]\n","            numel = param.numel()\n","\n","            grad_slice = noisy_avg_grad[current_idx : current_idx + numel]\n","\n","            if param.grad is None:\n","                param.grad = grad_slice.reshape(param.shape).detach().clone()\n","            else:\n","                param.grad.copy_(grad_slice.reshape(param.shape))\n","\n","            current_idx += numel\n","\n","        self.optimizer.step()\n","\n","        # ---- report batch loss ----\n","        with torch.no_grad():\n","            loss = loss_fn(self.model(x), y)\n","\n","        return loss.item()"],"metadata":{"id":"fxo9uQV9V9Ia"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Sampler\n","import random\n","\n","def sample_truncated_geometric(epsilon: float, delta: float) -> int:\n","    alpha = math.exp(epsilon)\n","    U = 0.5*math.log2(1/delta)/epsilon\n","\n","    # Sample from symmetric geometric\n","    # |r| ~ Geometric(p = 1 - 1/alpha)\n","    p = 1 - 1 / alpha\n","    magnitude = torch.distributions.Geometric(p).sample().item()\n","    sign = -1 if torch.rand(1).item() < 0.5 else 1\n","    r = sign * magnitude\n","\n","    # Truncate\n","    r = max(-U, min(U, r))\n","    return int(r)\n","\n","class TruncatedGeometricBatchSampler(Sampler):\n","    def __init__(self, dataset_size, mean_batch_size, epsilon, delta, shuffle=True):\n","        self.dataset_size = dataset_size\n","        self.mean_batch_size = mean_batch_size\n","        self.epsilon = epsilon\n","        self.delta = delta\n","        self.shuffle = shuffle\n","\n","    def __iter__(self):\n","        indices = list(range(self.dataset_size))\n","        if self.shuffle:\n","            random.shuffle(indices)\n","\n","        i = 0\n","        while i < self.dataset_size:\n","            noise = sample_truncated_geometric(self.epsilon/2, self.delta/2)\n","            batch_size = max(1, self.mean_batch_size + noise)\n","\n","            batch = indices[i:i + batch_size]\n","            yield batch\n","            i += batch_size\n","\n","    def __len__(self):\n","        # Approximate\n","        return self.dataset_size // self.mean_batch_size"],"metadata":{"id":"LAY-b6EAbhwc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iq6EokMRblgU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Jdd7fYDFblio"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()\n","def evaluate_model(model, dataloader, device=\"cpu\"):\n","    model.eval()\n","\n","    loss_fn = torch.nn.CrossEntropyLoss()\n","    total_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for x, y in dataloader:\n","        x, y = x.to(device), y.to(device)\n","        logits = model(x)\n","        loss = loss_fn(logits, y)\n","\n","        total_loss += loss.item() * x.size(0)\n","        preds = logits.argmax(dim=1)\n","        correct += (preds == y).sum().item()\n","        total += y.size(0)\n","\n","    return total_loss / total, correct / total"],"metadata":{"id":"TwE9GGnnTYkH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_TEST_LOADER_CACHE = {}\n","\n","def test_model(model, dataset_name=\"emnist\", batch_size=512, device=\"cpu\"):\n","    key = (dataset_name, batch_size)\n","\n","    if key not in _TEST_LOADER_CACHE:\n","        if dataset_name == \"emnist\":\n","            transform = transforms.Compose([transforms.ToTensor()])\n","            test_data = datasets.EMNIST(\n","                root=\"./data\",\n","                split=\"balanced\",\n","                train=False,\n","                download=True,\n","                transform=transform\n","            )\n","        elif dataset_name == \"cifar10\":\n","            transform = transforms.Compose([\n","                transforms.ToTensor(),\n","                transforms.Normalize(\n","                    mean=(0.4914, 0.4822, 0.4465),\n","                    std=(0.2023, 0.1994, 0.2010),\n","                ),\n","            ])\n","            test_data = datasets.CIFAR10(\n","                root=\"./data\",\n","                train=False,\n","                download=True,\n","                transform=transform\n","            )\n","        else:\n","            raise ValueError(\"Unsupported dataset\")\n","\n","        _TEST_LOADER_CACHE[key] = DataLoader(\n","            test_data,\n","            batch_size=batch_size,\n","            shuffle=False\n","        )\n","\n","    model.eval()\n","    with torch.no_grad():\n","        test_loss, test_acc = evaluate_model(\n","            model,\n","            _TEST_LOADER_CACHE[key],\n","            device=device\n","        )\n","\n","    print(\n","        f\"[{dataset_name.upper()}] \"\n","        f\"Test loss: {test_loss:.4f}, \"\n","        f\"Test accuracy: {test_acc*100:.2f}%\"\n","    )\n","\n","    return test_loss, test_acc"],"metadata":{"id":"306N-wzoXk0v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"q3glNFZ2Z3AI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","def make_train_loader(\n","    dataset,\n","    batch_size,\n","    shuffle=True,\n","    random_batch=False,\n","    epsilon=None,\n","    delta=None,\n","):\n","    if random_batch:\n","        if epsilon is None or delta is None:\n","            raise ValueError(\"epsilon and delta must be provided for random_batch\")\n","\n","        batch_sampler = TruncatedGeometricBatchSampler(\n","            dataset_size=len(dataset),\n","            mean_batch_size=batch_size,\n","            epsilon=epsilon,\n","            delta=delta,\n","            shuffle=shuffle,\n","        )\n","        return DataLoader(dataset, batch_sampler=batch_sampler)\n","    else:\n","        return DataLoader(\n","            dataset,\n","            batch_size=batch_size,\n","            shuffle=shuffle\n","        )\n"],"metadata":{"id":"YU66FsdJb3XZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RPhmv0VFMHXE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import random\n","\n","def set_seed(seed):\n","    torch.manual_seed(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)"],"metadata":{"id":"7wqhi0lAMHZN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from dataclasses import dataclass, field\n","from typing import List, Optional\n","\n","METHOD_CONFIG = {\n","    \"baseline\": {\n","        \"use_dp\": False,\n","        \"random_batch\": False,\n","    },\n","    \"Hamming-Style DP\": {\n","        \"use_dp\": True,\n","        \"random_batch\": False,\n","    },\n","    \"Edit-Style DP\": {\n","        \"use_dp\": True,\n","        \"random_batch\": True,\n","    },\n","}\n","\n","Dim_mapping={'emnist':47,'cifar10':10}\n","\n","@dataclass\n","class ExperimentLog:\n","    # identity\n","    method: str                    # REQUIRED\n","    dataset: str = \"\"\n","    seed: Optional[int] = None\n","\n","    # curves\n","    epochs: List[int] = field(default_factory=list)\n","    train_loss: List[float] = field(default_factory=list)\n","    test_loss: List[float] = field(default_factory=list)\n","    test_acc: List[float] = field(default_factory=list)\n","\n","    # DP metadata (None for baseline)\n","    agg_epsilon: Optional[float] = None\n","    agg_delta: Optional[float] = None\n","    bin_epsilon: Optional[float] = None\n","    bin_delta: Optional[float] = None\n","    dp_mechanism :str = 'NULL'"],"metadata":{"id":"bFNZMNo1MHbM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from dataclasses import dataclass\n","from typing import Optional, Dict, Any\n","\n","@dataclass\n","class LearningConfig:\n","    dataset: any\n","    batch_size: int\n","    epochs: int\n","    lr: float\n","    max_grad_norm:float\n","\n","    device: any\n","    loss_fn: any\n","    optimizer_class: any\n","    optimizer_kwargs: Optional[Dict[str, Any]] = None\n"],"metadata":{"id":"jQeGQT26MKQ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"j8u2W5wCMKSp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run_experiment(\n","    model,\n","    config: LearningConfig,\n","    log: ExperimentLog,\n","):\n","    assert log.method in METHOD_CONFIG, (\n","        f\"Unknown method '{log.method}'. \"\n","        f\"Available: {list(METHOD_CONFIG.keys())}\"\n","    )\n","\n","    cfg = METHOD_CONFIG[log.method]\n","    use_dp = cfg[\"use_dp\"]\n","    random_batch = cfg[\"random_batch\"]\n","\n","\n","    optimizer_kwargs = config.optimizer_kwargs or {}\n","\n","    # reproducibility\n","    if log.seed is not None:\n","        torch.manual_seed(log.seed)\n","        np.random.seed(log.seed)\n","        random.seed(log.seed)\n","\n","    train_loader = make_train_loader(\n","        dataset=config.dataset,\n","        batch_size=config.batch_size,\n","        random_batch=random_batch,\n","        epsilon=log.bin_epsilon if log.agg_epsilon else None,\n","        delta=log.bin_delta if log.agg_delta else None\n","    )\n","\n","    optimizer = config.optimizer_class(\n","        model.parameters(),\n","        lr=config.lr,\n","        **optimizer_kwargs,\n","    )\n","\n","    if use_dp:\n","        trainer = DPSGDTrainer(\n","            model=model,\n","            optimizer=optimizer,\n","            epsilon=log.agg_epsilon,\n","            delta=log.agg_delta,\n","            device=config.device,\n","            max_grad_norm=config.max_grad_norm,\n","            dp_mechanism=log.dp_mechanism\n","\n","        )\n","        print(\n","            f\"Running {log.method} | \"\n","            f\"random_batch={random_batch}, agg_epsilon={log.agg_epsilon}, agg_delta={log.agg_delta}\"\n","        )\n","    else:\n","        trainer = NormalTrainer(\n","            model=model,\n","            optimizer=optimizer,\n","            device=config.device,\n","            max_grad_norm=config.max_grad_norm\n","        )\n","        print(\"Running baseline (non‑DP)\")\n","\n","    model.to(config.device)\n","\n","    for epoch in range(1, config.epochs + 1):\n","        model.train()\n","\n","        if use_dp:\n","            trainer.reset_presum()\n","\n","        total_loss = 0.0\n","        for x, y in train_loader:\n","            loss = trainer.train_batch(x, y, config.loss_fn)\n","            total_loss += loss\n","\n","        avg_loss = total_loss / len(train_loader)\n","\n","        log.epochs.append(epoch)\n","        log.train_loss.append(avg_loss)\n","\n","        model.eval()\n","        with torch.no_grad():\n","            test_loss, acc = test_model(\n","                model=model,\n","                dataset_name=log.dataset,\n","                batch_size=config.batch_size,\n","                device=config.device,\n","            )\n","\n","        log.test_loss.append(test_loss)\n","        log.test_acc.append(acc)\n","\n","        print(\n","            f\"Epoch {epoch}/{config.epochs} | \"\n","            f\"Train loss: {avg_loss:.4f}\"\n","        )\n","\n","    return model, log"],"metadata":{"id":"l-_T7Yhgrhkw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lgCIOUMqMOCL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MspsxwVHMOEG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run_vision_experiment(\n","    *,\n","    dataset_name: str,              # 'emnist' | 'cifar10'\n","    method: str,                    # 'baseline' | 'Hamming-Style DP' | 'Edit-Style DP'\n","    batch_size: int = 256,\n","    epochs: int = 5,\n","    lr: float = 0.1,\n","    sigma: float = None,\n","    agg_epsilon: float = None,\n","    agg_delta: float = None,\n","    bin_epsilon : float = None,\n","    bin_delta : float = None,\n","    seed: int = 0,\n","    max_grad_norm: float =1,\n","    dp_mechanism='Naive',\n","    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n","):\n","    # ── dataset ────────────────────────────────────────────\n","    if dataset_name == \"emnist\":\n","\n","      transform = transforms.Compose([\n","          transforms.ToTensor(),\n","          transforms.Lambda(lambda x: torch.rot90(x, 1, [1, 2])),\n","          transforms.Lambda(lambda x: torch.flip(x, [2])),\n","          transforms.Normalize((0.5,), (0.5,)),\n","      ])\n","\n","        train_dataset = datasets.EMNIST(\n","            root=\"./data\",\n","            split=\"balanced\",\n","            train=True,\n","            download=True,\n","            transform=transform,\n","        )\n","\n","        model = SimpleCNN(num_classes=47,in_channels=1)\n","\n","    elif dataset_name == \"cifar10\":\n","        transform = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize(\n","                mean=(0.4914, 0.4822, 0.4465),\n","                std=(0.2023, 0.1994, 0.2010),\n","            ),\n","        ])\n","\n","        train_dataset = datasets.CIFAR10(\n","            root=\"./data\",\n","            train=True,\n","            download=True,\n","            transform=transform,\n","        )\n","\n","        model = SimpleCNN(num_classes=10,in_channels=3)\n","\n","    else:\n","        raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n","\n","    # ── learning config (training mechanics only) ──────────\n","    config = LearningConfig(\n","        dataset=train_dataset,\n","        batch_size=batch_size,\n","        epochs=epochs,\n","        lr=lr,\n","        device=device,\n","        loss_fn=nn.CrossEntropyLoss(),\n","        optimizer_class=torch.optim.SGD,\n","        optimizer_kwargs={},\n","        max_grad_norm=max_grad_norm\n","    )\n","\n","    # ── experiment log (method + privacy) ──────────────────\n","    log = ExperimentLog(\n","        method=method,\n","        dataset=dataset_name,\n","        seed=seed,\n","        agg_epsilon=agg_epsilon,\n","        agg_delta=agg_delta,\n","        bin_epsilon=bin_epsilon,\n","        bin_delta=bin_delta,\n","        dp_mechanism=dp_mechanism\n","    )\n","\n","    # ── run ────────────────────────────────────────────────\n","    return run_experiment(\n","        model=model,\n","        config=config,\n","        log=log,\n","    )"],"metadata":{"id":"gEqMpf6Hb3Zb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model,log=run_vision_experiment(\n","    dataset_name=\"emnist\",\n","    method=\"baseline\",\n","    epochs=50,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":633},"id":"0eSh07zWWz54","executionInfo":{"status":"error","timestamp":1768301225793,"user_tz":-480,"elapsed":341034,"user":{"displayName":"Mengshi ZHAO","userId":"09447597087433299627"}},"outputId":"87fc4143-537a-4045-a1ef-7b6d0cd902b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Running baseline (non‑DP)\n","[EMNIST] Test loss: 3.5001, Test accuracy: 17.78%\n","Epoch 1/50 | Train loss: 3.7999\n","[EMNIST] Test loss: 2.2816, Test accuracy: 36.04%\n","Epoch 2/50 | Train loss: 2.6463\n","[EMNIST] Test loss: 2.1106, Test accuracy: 41.62%\n","Epoch 3/50 | Train loss: 2.1007\n","[EMNIST] Test loss: 2.0323, Test accuracy: 46.22%\n","Epoch 4/50 | Train loss: 1.9666\n","[EMNIST] Test loss: 1.9890, Test accuracy: 48.99%\n","Epoch 5/50 | Train loss: 1.9004\n","[EMNIST] Test loss: 1.9815, Test accuracy: 50.20%\n","Epoch 6/50 | Train loss: 1.8724\n","[EMNIST] Test loss: 1.9637, Test accuracy: 52.66%\n","Epoch 7/50 | Train loss: 1.8600\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4154200904.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model,log=run_vision_experiment(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"emnist\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"baseline\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n","\u001b[0;32m/tmp/ipython-input-3886628037.py\u001b[0m in \u001b[0;36mrun_vision_experiment\u001b[0;34m(dataset_name, method, batch_size, epochs, lr, sigma, agg_epsilon, agg_delta, bin_epsilon, bin_delta, seed, max_grad_norm, dp_mechanism, device)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# ── run ────────────────────────────────────────────────\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     return run_experiment(\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-2675592723.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(model, config, log)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["model,log=run_vision_experiment(\n","    dataset_name=\"emnist\",\n","    method=\"Hamming-Style DP\",\n","    agg_epsilon=1000,\n","    agg_delta=1e-5,\n","    epochs=20,\n","    lr=0.1\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":847},"id":"ggwzJWSKWz8f","executionInfo":{"status":"error","timestamp":1768300268576,"user_tz":-480,"elapsed":714398,"user":{"displayName":"Mengshi ZHAO","userId":"09447597087433299627"}},"outputId":"c353e697-2993-4c91-b143-a2791bb5e90d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Running Hamming-Style DP | random_batch=False, agg_epsilon=1000, agg_delta=1e-05\n","[EMNIST] Test loss: 3.5670, Test accuracy: 15.51%\n","Epoch 1/20 | Train loss: 3.8134\n","[EMNIST] Test loss: 2.3219, Test accuracy: 34.40%\n","Epoch 2/20 | Train loss: 2.7003\n","[EMNIST] Test loss: 2.1502, Test accuracy: 40.27%\n","Epoch 3/20 | Train loss: 2.1395\n","[EMNIST] Test loss: 2.0691, Test accuracy: 45.11%\n","Epoch 4/20 | Train loss: 2.0030\n","[EMNIST] Test loss: 2.0223, Test accuracy: 48.08%\n","Epoch 5/20 | Train loss: 1.9299\n","[EMNIST] Test loss: 2.0047, Test accuracy: 49.51%\n","Epoch 6/20 | Train loss: 1.8952\n","[EMNIST] Test loss: 1.9878, Test accuracy: 51.64%\n","Epoch 7/20 | Train loss: 1.8753\n","[EMNIST] Test loss: 1.9955, Test accuracy: 53.17%\n","Epoch 8/20 | Train loss: 1.8684\n","[EMNIST] Test loss: 1.9874, Test accuracy: 54.64%\n","Epoch 9/20 | Train loss: 1.8694\n","[EMNIST] Test loss: 2.0392, Test accuracy: 55.02%\n","Epoch 10/20 | Train loss: 1.8710\n","[EMNIST] Test loss: 2.0262, Test accuracy: 56.56%\n","Epoch 11/20 | Train loss: 1.8757\n","[EMNIST] Test loss: 2.0383, Test accuracy: 56.43%\n","Epoch 12/20 | Train loss: 1.8802\n","[EMNIST] Test loss: 2.0227, Test accuracy: 58.03%\n","Epoch 13/20 | Train loss: 1.8756\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1302721131.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model,log=run_vision_experiment(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"emnist\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Hamming-Style DP\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0magg_epsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0magg_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3886628037.py\u001b[0m in \u001b[0;36mrun_vision_experiment\u001b[0;34m(dataset_name, method, batch_size, epochs, lr, sigma, agg_epsilon, agg_delta, bin_epsilon, bin_delta, seed, max_grad_norm, dp_mechanism, device)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# ── run ────────────────────────────────────────────────\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     return run_experiment(\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-2675592723.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(model, config, log)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1405656668.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, x, y, loss_fn)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# ---- YOUR privacy mechanism (UNCHANGED) ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0msummed_grad_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummed_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmechanism\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummed_grad_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mnoisy_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmechanism\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["model,log=run_vision_experiment(\n","    dataset_name=\"emnist\",\n","    method=\"Edit-Style DP\",\n","    epsilon=0.1,\n","    delta=0.1,\n","    epochs=10,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E8iarcqJaRYy","executionInfo":{"status":"ok","timestamp":1768208342123,"user_tz":-480,"elapsed":183071,"user":{"displayName":"Mengshi ZHAO","userId":"09447597087433299627"}},"outputId":"6e488514-f56c-416b-d990-73c858b4dd2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Running Edit-Style DP | sigma=0.1, random_batch=True, epsilon=0.1, delta=0.1\n","[EMNIST] Test loss: 2.0147, Test accuracy: 41.31%\n","Epoch 1/10 | Train loss: 3.0736\n","[EMNIST] Test loss: 1.6082, Test accuracy: 55.79%\n","Epoch 2/10 | Train loss: 1.5873\n","[EMNIST] Test loss: 1.8818, Test accuracy: 56.23%\n","Epoch 3/10 | Train loss: 1.3618\n","[EMNIST] Test loss: 1.8795, Test accuracy: 59.58%\n","Epoch 4/10 | Train loss: 1.4426\n","[EMNIST] Test loss: 2.3390, Test accuracy: 56.26%\n","Epoch 5/10 | Train loss: 1.4965\n","[EMNIST] Test loss: 2.3132, Test accuracy: 56.65%\n","Epoch 6/10 | Train loss: 1.6029\n","[EMNIST] Test loss: 2.1506, Test accuracy: 54.42%\n","Epoch 7/10 | Train loss: 1.7192\n","[EMNIST] Test loss: 2.3639, Test accuracy: 53.05%\n","Epoch 8/10 | Train loss: 1.7409\n","[EMNIST] Test loss: 2.8182, Test accuracy: 49.66%\n","Epoch 9/10 | Train loss: 1.8314\n","[EMNIST] Test loss: 2.5849, Test accuracy: 51.28%\n","Epoch 10/10 | Train loss: 1.9204\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"W8dAXzxuXjHy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"metadata":{"id":"EvRv--gZLZIn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def logs_to_df(logs):\n","    records = []\n","    for log in logs:\n","        if len(log.test_acc) == 0:\n","            continue\n","        records.append({\n","            \"dataset\": log.dataset,\n","            \"method\": log.method,\n","            \"epsilon\": log.epsilon,\n","            \"sigma\": log.sigma,\n","            \"seed\": log.seed,\n","            \"final_acc\": log.test_acc[-1],\n","        })\n","    return pd.DataFrame(records)"],"metadata":{"id":"4EAL05ukMXvh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_acc_vs_epsilon(df, dataset):\n","    plt.figure(figsize=(6, 4))\n","    sns.lineplot(\n","        data=df[df[\"dataset\"] == dataset],\n","        x=\"epsilon\",\n","        y=\"final_acc\",\n","        hue=\"method\",\n","        marker=\"o\",\n","        errorbar=\"sd\",\n","    )\n","    plt.xscale(\"log\")\n","    plt.xlabel(\"Privacy budget ε\")\n","    plt.ylabel(\"Test accuracy\")\n","    plt.title(f\"{dataset}: Accuracy vs Privacy Budget\")\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"_nt1J6EFMZO3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_learning_curve(\n","    logs,\n","    dataset,\n","    method,\n","    epsilon,\n","):\n","    curves = [\n","        log for log in logs\n","        if log.dataset == dataset\n","        and log.method == method\n","        and log.epsilon == epsilon\n","    ]\n","\n","    accs = np.array([log.test_acc for log in curves])\n","    mean = accs.mean(axis=0)\n","    std = accs.std(axis=0)\n","\n","    epochs = curves[0].epochs\n","\n","    plt.figure(figsize=(6, 4))\n","    plt.plot(epochs, mean, label=method)\n","    plt.fill_between(\n","        epochs,\n","        mean - std,\n","        mean + std,\n","        alpha=0.3,\n","    )\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Test accuracy\")\n","    plt.title(f\"{dataset} Learning Curve (ε={epsilon})\")\n","    plt.legend()\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"-j5eF6GMMbMF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Pjicx8cKMfdJ"},"execution_count":null,"outputs":[]}]}